# Optimize computer vision models

Практика по курсу "Оптимизация моделей компьютерного зрения"  
### Задание 1. 
Подготовка окружения и обучение простого классификатора на учебном датасете, например, cifar10.  

### Задание 2. 
Сравнить скорость сходимости для разных алгоритмов оптимизации. 
Результат обучения в виде графиков loss/epoch отобразить на ОДНОМ изображении и разместить в своем файле Readme. 
Снабдить пояснениями и выводами. 
|ФИО | Алгоритмы для сравнения |
|------------------------------|-----------------|
| Асеев Дмитрий   Андреевич    | SGD, AdaGrad    |
| Вилкул Анна Андреевна        | SGD, Adamax     |
| Добровольский Роман Олегович | SGD, Rprop      |
| Макаров Иван Сергеевич       | SGD, AdamW      |
| Рябинкин Валерий Николаевич  | SGD, SparseAdam |
| Черевко Кирилл Николаевич    | SGD, Adam       |
| Юрин Дмитрий Сергеевич       | SGD, RMSprop    |


### Задание 3. 
Оптимизация гиперпараметров с помощью optune.  
За основу берем [скрипт](https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py)  
Заменяем линейную сеть на сверточную Conv2D - Flatten - {Linear - ReLU - Dropout} * n_layers  
Датасет Cifar10.  
Поиск осуществляем по двум гиперпараметрам согласно таблицы.  
|ФИО | Гиперпараметры |
|------------------------------|-----------------|
| Асеев Дмитрий   Андреевич    | ("n_layers", 1, 5) ; ("lr", 1e-5, 1e-1, log=True)    |
| Вилкул Анна Андреевна        | Conv2D("kernel_size", 3, 7) ; ("lr", 1e-5, 1e-1, log=True)        |
| Добровольский Роман Олегович | ("dropout", 0.2, 0.5) ; ("optimizer", ["Adam", "RMSprop", "SGD"])       |
| Макаров Иван Сергеевич       |  ("n_units", 4, 128) ;  ("n_layers", 1, 5)    |
| Рябинкин Валерий Николаевич  | Conv2D("kernel_size", 3, 7) ; ("optimizer", ["Adam", "RMSprop", "SGD"]) |
| Черевко Кирилл Николаевич    | Conv2D("kernel_size", 3, 7) ; ("n_layers", 1, 5)      |
| Юрин Дмитрий Сергеевич       | ("dropout", 0.2, 0.5) ;  ("lr", 1e-5, 1e-1, log=True)   |

